---
title: "Milestone Report"
subtitle: "Data Science Capstone <br> Johns Hopkins / Coursera"
author: "Michael Liquori"
date: "Saturday, November 15, 2014"
output: html_document
---
<hr>

### Background

The aim of this project is to develop a model that will allow us to predict the next word a user intends to type to aid in faster typing, similar to the feature currently embedded in most smartphones. We will seek to balance speed and accuracy in developing an algorithm which is competitive with the current word-prediction keyboards available, such as "SwiftKey".

The data provided for NLP (Natural Language Processing) consists of 3 "corpora" of data, one collected from <font color="red" face="bold">**blog posts**</font>, one from <font color="orange" face="bold">**news articles**</font>, and a third from <font color="skyblue" face="bold">**twitter messages**</font> ("tweets"). 

### Exploratory Analysis

We begin by analyzing some basic facts about each corpus such as number of lines, number of words, number of unique words, line length, and average unique word length.

#### Number of Lines, Words, and Words per Line

```{r, echo=FALSE,warning=FALSE,message=FALSE}

# SETUP #
setwd("C:/Users/Michael/SkyDrive/Code/GitHub/DSCapstone/Coursera-SwiftKey/final/en_US")
library(tm)
load("C:/Users/Michael/SkyDrive/Code/GitHub/DSCapstone/Coursera-SwiftKey/final/en_US/RanMdownScriptFullProcessing.RData")

# Line counts

tlCount=2360148
nlCount=1010242
blCount=899288

# Number of Total Words

twCount=30373583
nwCount=34372530
bwCount=37334131

# Number of words per line
tnwl=twCount/tlCount
nnwl=nwCount/nlCount
bnwl=bwCount/blCount

# Get maximum line length

tlmount=173
nlmount=11384
blmount=40833

# Get unique words unstemmed

tuw<-1192198
nuw<-750174
buw<-952939

# Number of Unique Words STEMMED

tuwCount=454293
buwCount=355364
nuwCount=79427

# Plot

# 3 corpora in one plot barplots:

## Shared parameters

# save par defaults first
op<-par()

names=c("Twitter Corpus", "News Corpus", "Blogs Corpus")
colors=c("cadetblue3","chocolate2","firebrick1")
par(mai=c(1,2,1,1))

## Number of Lines

counts=c(tlCount,blCount,nlCount)
bp<-barplot(counts, col=colors, main="Number of Lines", horiz=TRUE, names.arg=names, las=1, axes=FALSE)
axis(1, at = c(0,500000,1000000,1500000,2000000), labels=c("0","500,000","1,000,000","1,500,000","2,000,000"))
text(0,bp,prettyNum(counts,big.mark=",",scientific=F),cex=1.3,pos=4) 
```

We see that the <font color="skyblue" face="bold">**twitter corpus**</font> has many more lines than the others. But how many words are in each line?

```{r, echo=FALSE,warning=FALSE,message=FALSE}

## Average Number of Words per Line
par(mai=c(1,2,1,1))
counts=c(tnwl,bnwl,nnwl)
bp<-barplot(counts, col=colors, main="Average Number of Words per Line", horiz=TRUE, names.arg=names, las=1, axes=FALSE, xlim=c(0,50))
axis(1, at = seq(0,50,by=10))
text(0,bp,prettyNum(counts,big.mark=",",scientific=F),cex=1.3,pos=4) 
```

We see that lines are much shorter in the <font color="skyblue" face="bold">**twitter corpus**</font> and longest in the <font color="orange" face="bold">**news corpus**</font>. 

But, what exactly do lines represent? In the <font color="skyblue" face="bold">**twitter corpus**</font> they seem to represent one tweet, which has a clearly defined limit of 140 characters. In the <font color="red" face="bold">**blogs**</font> and <font color="orange" face="bold">**news corpus**</font>, they are less defined, sometimes representing just one sentence, sometimes an entire paragraph. 

Let's also check the total number of words in each corpus:

```{r, echo=FALSE,warning=FALSE,message=FALSE}
## Total Words
par(mai=c(1,2,1,1))
counts=c(twCount,bwCount,nwCount)
bp<-barplot(counts, col=colors, main="Total Words per Corpus", horiz=TRUE, names.arg=names, las=1, axes=FALSE)
axis(1, at=seq(0,40000000,by=10000000),labels=formatC(seq(0,40000000,by=10000000),format="f", digits=0))
text(0,bp,prettyNum(counts,big.mark=",",scientific=F),cex=1.3,pos=4) 
```

#### Diversity of Vocabulary

Now let's examine the diversity of unique words used in each corpus. There are two different measures we will use: **stemmed** and **unstemmed**. Stemming reduces words to their root, so, for example, "walking, walked, walker" would all become simply "walk" and be counted as one unique word. Unstemmed, they would count as 3 unique words.

```{r, echo=FALSE,warning=FALSE,message=FALSE}
## Number of Unique Words Stemmed
par(mai=c(1,2,1,1))
counts=c(tuwCount,buwCount,nuwCount)
bp<-barplot(counts, col=colors, main="Number of Stemmed Unique Words", horiz=TRUE, names.arg=names, las=1, axes=FALSE, xlim=c(0,500000))
axis(1, at = c(0,100000,200000,300000,400000,500000), labels=c(0,"100,000","200,000","300,000","400,000","500,000"))
text(0,bp,prettyNum(counts,big.mark=",",scientific=F),cex=1.3,pos=4) 
## Number of Unique Words Unstemmed
counts=c(tuw,buw,nuw)
bp<-barplot(counts, col=colors, main="Number of Unstemmed Unique Words", horiz=TRUE, names.arg=names, las=1, axes=FALSE, xlim=c(0,1500000))
axis(1, at = seq(0,1500000,by=250000), labels=prettyNum(seq(0,1500000,by=250000),big.mark=",",scientific=F))
text(0,bp,prettyNum(counts,big.mark=",",scientific=F),cex=1.3,pos=4) 

```

The diversity of words in <font color="red" face="bold">**blogs**</font> seems extremely low from our stemmed analysis, but the unstemmed number brings it closer in line with the other corpora. This suggests that used in <font color="red" face="bold">**blogs**</font> are very low, while they are highest in <font color="skyblue" face="bold">**twitter**</font>. What about the length of the average (unstemmed) word used?

```{r, echo=FALSE,warning=FALSE,message=FALSE}
## Average Unique Word Length
par(mai=c(1,2,1,1))
tAvg=4.479
bAvg=4.563
nAvg=4.943
counts=c(tAvg,bAvg,nAvg)
bp<-barplot(counts, col=colors, main="Average Unique Word Length", horiz=TRUE, names.arg=names, las=1, axes=FALSE, xlim=c(0,10))
axis(1, at = c(0,2.5,5,7.5,10), labels=c(0,2.5,5,7.5,10))
text(0,bp,prettyNum(counts,big.mark=",",scientific=F),cex=1.3,pos=4) 
```

As one would probably expect, the <font color="skyblue" face="bold">**twitter corpus**</font> contains the shortest words, due do its character limit and the nature of short-form communication it is intended to be used for, while <font color="red" face="bold">**blogs**</font> have the longest, due probably to a lack of any editor or other constraints on the writer. But, the differences are not all that great.

Now let's look at the distribution of word frequencies, ignoring the higher word counts where there are very few examples:

```{r, echo=FALSE,warning=FALSE,message=FALSE}
# Histogram for each corpus barplots:

## Word length Frequency Histograms for each Corpus
setwd("C:/Users/Michael/SkyDrive/Code/GitHub/DSCapstone/Coursera-SwiftKey/final/en_US")
twLengths=readRDS("twLengths")
bwLengths=readRDS("bwLengths")
nwLengths=readRDS("nwLengths")
par(mfcol=c(3,1))
hist(bwLengths, col ="firebrick1", breaks=seq(0,max(bwLengths),by=1), main="Blogs Corpus Word-Lengths", xlab = "Values", cex.lab = 1.3,xlim=c(0,25))

hist(nwLengths, col ="chocolate2", breaks=seq(0,max(nwLengths),by=1), main="News Corpus Word-Lengths", xlab = "Values", cex.lab = 1.3,xlim=c(0,25))

hist(twLengths, col ="cadetblue3", breaks=seq(0,max(twLengths),by=1), main="Twitter Corpus Word-Lengths", xlab = "Values", cex.lab = 1.3, xlim=c(0,25))
```

We see that the distribution of word lengths are very similar. 

Now, an example of the 10 most common words in each corpora. This is after processing both stemming and eliminating very common words such as "the", which are called "stop words" in language processing.
```{r, echo=FALSE,warning=FALSE,message=FALSE}
setwd("C:/Users/Michael/SkyDrive/Code/GitHub/DSCapstone/Coursera-SwiftKey/final/en_US")
bTop=readRDS("bTop")
tTop=readRDS("tTop")
nTop=readRDS("nTop")

# plot
barplot(bTop, col ="firebrick1", main="Top 10 Words: Blogs Corpus", xlab = "Frequency", cex.lab = 1.3, horiz=TRUE, las=1)

barplot(nTop, col ="chocolate2", main="Top 10 Words: News Corpus", xlab = "Frequency", cex.lab = 1.3,horiz=TRUE, las=1)

barplot(tTop, col ="cadetblue3", main="Top 10 Words: Twitter Corpus", xlab = "Frequency", cex.lab = 1.3, horiz=TRUE, las=1)
```

### Next Steps: Developing A Prediction Algorithm

We can see even from just the top 10 words in each corpus that there are significant differences between the corpora, with words like "love" and "thank" scoring highly in <font color="skyblue" face="bold">**twitter**</font>, while "state" scores highly in <font color="orange" face="bold">**news**</font>.  Also, "said" scores extremely highly in the <font color="orange" face="bold">**news corpus**</font>, due to frequent use of quotations in news articles, which may mean that this corpus may more closely mirror the way people actually speak, rather than how they write.

So, one important aspect of our algorithm may be to try and determine which type of message is being written - for <font color="red" face="bold">**blog**</font>, <font color="orange" face="bold">**news**</font>, or <font color="skyblue" face="bold">**twitter**</font> type of communications. One of the basic rules of machine learning is that you are likely to get good prediction results only if the data you train your algorithm on is of the same type as your test data (Source: *Stanford NLP Course on Coursera*).

First, we will aim to identify the type of communication we are dealing with by examining the words used and seeing how common they are in each corpus. Next, we will search in that corpus for trigrams (3-word phrases) where the first two words match the last two words of our prediction query. Next we will look to bigrams, and finally the probability of individual words may play a role in our prediction. 

In some cases, unusual words which are at the beginning of the sentence may play an important role in prediction, so we should also include a method which considers these words and searches among a corpus of other sentences which include those words.

We will also need to remove sparse words in order to increase the speed of our algorithm, and testing will need to be done to see where the appropriate balance of speed and accuracy lies.