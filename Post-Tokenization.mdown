Post-Tokenization
====
# Idea
Load the test sentence as a TDM.
Use findAssoc to get words?

```r
#Set working directory
setwd("C:/Users/Michael/SkyDrive/Code/GitHub/DSCapstone/Coursera-SwiftKey/final/en_US")

fileName="testData.txt"
testData <- readLines(fileName)

## REMOVAL OF STRANGE CHARACTERS##
# Replace unicode characters with spaces.
cleanData<-iconv(testData, to='ASCII', sub=' ')
# Replace numbers and ''
cleanData2 <- gsub("'{2}", " ", cleanData)
cleanData3 <- gsub("[0-9]", " ", cleanData2)

## MAKE CORPUS ##
require(tm)
corpus <- Corpus(VectorSource(cleanData3))

## TOKENIZATION ## 

# REMOVE WHITESPACE:
corpus1 <- tm_map(corpus, stripWhitespace)
inspect(corpus1) #don't see a big difference

# LOWERCASE:
corpus2 <- tm_map(corpus1, content_transformer(tolower))
inspect(corpus2) #works

# REMOVE STOPWORDS
corpus3 <- tm_map(corpus2, removeWords, stopwords("english"))
inspect(corpus3) # ok the has been removed...

# STEMMING
corpus4 <- tm_map(corpus3, stemDocument)
inspect(corpus4) # Looks stemmed.

# REMOVE PUNCTUATION
corpus5<- tm_map(corpus4,removePunctuation)

# REMOVE NUMBERS
corpus6<- tm_map(corpus5,removeNumbers)

## END TOKENIZATION ##

## TOKEN ANALYSIS ##

# MAKE TERM DOCUMENT MATRIX (TDM) - a matrix of frequency counts for each word used in the corpus.
tdm<- TermDocumentMatrix(corpus6)
dtm<- DocumentTermMatrix(corpus6)
dtm

```

# Implement "Bag of Words" model

I need to weight the words.


[](http://anythingbutrbitrary.blogspot.com/2013/03/build-search-engine-in-20-minutes-or.html)

# SOME COMMANDS:

```r
findFreqTerms(x = tdm, lowfreq=58, highfreq=Inf)
findAssocs(x=tdm,term="also",corlimit=0.1)

# 1. take a sentence and iterate through the words

# 2. Look up associated words 

# 3. Give a score to each association with higher score to the words near the blank. 

## POSSIBILITIES:

# 1. REMOVE SPARSE TERMS
TDM.common = removeSparseTerms(TDM, 0.1)
dim(TDM)
# [1] 18651   182
dim(TDM.common)
# [1]  71 182
```

# Quiz 2
## Question 1
The guy in front of me just bought a pound of bacon, a bouquet, and a case of
soda
pretzels
cheese
beer

# Vocab
*orthogonal* - right-angle but in statistics means not related.
*dot product* - an algebraic operation that takes two equal-length sequences of numbers (usually coordinate vectors) and returns a single number.
*Euclidean space* - encompasses the two-dimensional Euclidean plane, the three-dimensional space of Euclidean geometry, and certain other spaces
